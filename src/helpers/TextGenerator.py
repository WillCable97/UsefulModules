import tensorflow as tf
import numpy as np

from src.data.Text.Tokens.BaseClass import TokenBaseClass



"""
    1- Input Handler: Takes input either as string or token and creates input to the model 
        (different sublasses account for different expectations in the formatting of the data assumed by the model)
        (Deals with tokeniser for all domains)
    
    2- Model Handler: Runs inputs through inderence pass
       Can determine latest token in the output

    3- Text Generator: Takes output from the model to keep track of the generated text
       (results are passed back to the input handler)
    
    
    Generated Text: Tracks text generated by the model and will maintain the output to be passed back into the next iteration of the model
       Deals with tokeniser of the output of the model 
       (takes into account the length of the content to ensure that there is no overflow being passed into model evaluation call)
"""




class TextGenerator:
    def __init__(self, input_string: str, output_tokeniser = TokenBaseClass, input_model, aux_inputs = None, aux_tokens = None):
        input_handle = InputHandler(input_string, output_tokeniser, aux_inputs, aux_tokens)
        model_handle = ModelHandler(input_model)
        output_handler = OutputHandler(output_tokeniser)

    def generate_output(self, max_len: int, termination_token: int = None):
        for i in range(max_len):
            model_input = input_handler.get_input()
            model_output = model_handle.get_output(model_input)
            token = model_output.get_max_token()
            output_handler.add_token(token)
            input_handle.update_input(output_handler.get_input_vector())

        return output_handler.final_output()
        


from typing import Union

class SingleInputHandler:
    def __init__(self, input: Union[str, tf.Tensor], input_tokeniser: TokenBaseClass, seq_len = None):
        self.input = input
        self.input_tokeniser = input_tokeniser
        self.seq_len = seq_len
        self.formatted_input = self.convert_initial_input()

    def convert_initial_input(self) -> tf.Tensor:
        output = string_to_tokens(self.input, self.input_tokeniser, self.seq_len) if isinstance(self.input, str) else self.input
        return output

    def update_input(self, new_token):
        pass


class GeneralInputHandlers:
    def __init__(self, input_string: str, output_tokeniser = TokenBaseClass, input_model, aux_inputs = None, aux_tokens = None):
        pass









class StandardRecursionInput:
    def __init__(self, input: Union[str, tf.Tensor], input_tokeniser: TokenBaseClass, seq_len = None):
        self.input = input
        self.input_tokeniser = input_tokeniser
        self.seq_len = seq_len
        self.model_input = self.convert_initial_input()

    def convert_initial_input(self) -> tf.Tensor:
        output = string_to_tokens(self.input, self.input_tokeniser, self.seq_len) if isinstance(self.input, str) else self.input
        return output

    def load_in_generated_tokens(self, input_tokens: tf.Tensor) -> None:
        #this is the text from the generated text object
        self.model_input = input_tokens










class InputHandler(Protocol):
    def convert_initial_input(self):
        ...


    def load_in_generated_tokens(self, input_tokens: tf.Tensor):
        ...


class StandardRecursionInput:
    def __init__(self, input: Union[str, tf.Tensor], input_tokeniser: TokenBaseClass, seq_len = None):
        self.input = input
        self.input_tokeniser = input_tokeniser
        self.seq_len = seq_len
        self.model_input = self.convert_initial_input()

    def convert_initial_input(self) -> tf.Tensor:
        output = string_to_tokens(self.input, self.input_tokeniser, self.seq_len) if isinstance(self.input, str) else self.input
        return output

    def load_in_generated_tokens(self, input_tokens: tf.Tensor) -> None:
        #this is the text from the generated text object
        self.model_input = input_tokens


class TransformerRecursionInput:
    def __init__(self, context_input: Union[str, tf.Tensor], context_tokeniser: TokenBaseClass
                 , content_input: Union[str, tf.Tensor], content_tokeniser: TokenBaseClass
                 , context_seq_len: int):
        #Context Variables (String input)
        self.context_input = context_input
        self.context_tokeniser = context_tokeniser
        self.context_input_object = StandardRecursionInput(self.context_input, self.context_tokeniser, context_seq_len)
        self.context_tokens = self.context_input_object.convert_initial_input()

        #Content Variables (Where output is handeled)
        self.content_input = content_input
        self.content_tokeniser = content_tokeniser
        self.content_input_object = StandardRecursionInput(self.content_input, self.content_tokeniser)

        #Inputs
        self.model_input = self.convert_initial_input()


    def convert_initial_input(self) -> tf.Tensor:
        output = tf.concat([self.context_tokens, self.context_input_object.convert_initial_input()], axis=0)
        return output
        
    def  load_in_generated_tokens(self, input_tokens: tf.Tensor) -> None:
        self.model_input = tf.concat([self.context_tokens, input_tokens], axis=0)


